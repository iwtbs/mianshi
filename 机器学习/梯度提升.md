# 梯度提升（Gradient Boosting）
##  梯度提升和提升树的区别和联系
提升树利用加法模型与前向分歩算法实现学习的优化过程。当损失函数是**平方误差损失函数**和**指数损失函数**时，每一步优化是很简单的。但对**一般损失函数**而言，往往每一步优化并不那么容易。针对这一问题，Freidman提出了梯度提升（gradient boosting）算法。它的思想借鉴于梯度下降法，其基本原理是根据当前模型损失函数的**负梯度信息**作为提升树算法中残差的近似值，拟合一个梯度提升模型
## 梯度提升与梯度下降的区别和联系是什么？
两者都是在每一轮迭代中，利用损失函数相对于模型的负梯度方向的信息来对当前模型进行更新，只不过在梯度下降中，模型是以参数化形式表示，从而模型的更新等价于参数的更新。而在梯度提升中，模型并不需要进行参数化表示，而是直接定义在函数空间中，从而大大扩展了可以使用的模型种类。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200223225755141.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0MjE5OTU5,size_16,color_FFFFFF,t_70)
## 梯度提升和GBDT的区别和联系？

- 采用决策树作为弱分类器的Gradient Boosting算法被称为GBDT，有时又被称为MART（Multiple Additive Regression Tree）。GBDT中使用的决策树通常为CART。
- GBDT使用梯度提升（Gradient Boosting）作为训练方法。
## 梯度提升原理推导
[推导](https://mp.weixin.qq.com/s/Ods1PHhYyjkRA8bS16OfCg)
## 梯度提升算法包含哪些算法？
Gradient Boosting是Boosting中的一大类算法，其中包括：GBDT（Gradient Boosting Decision Tree）、XGBoost（eXtreme Gradient Boosting）、LightGBM （Light Gradient Boosting Machine）和CatBoost（Categorical Boosting）等