# 特征工程
## 为什么要归一化
归一化可以提高收敛速度，提高收敛的精度

归一化：最大值、均值
标准化：Z-score
离散化：分段，等频等距
## 类别型特征编码
1. 序号编码
适合有大小关系的
2. 独热编码
- 使用稀疏向量节省空间
- 配合特征选择来降低维度
3. 二进制编码
本质是利用二进制进行哈希映射
## 如何处理高维组合特征
将用户和物品分别用k维的低维向量表示。
m*n —> m*k + n*k
(其实就是推荐中的矩阵分解)
## 常见距离度量方式有哪些？
1. 曼哈顿距离
L1范数
![在这里插入图片描述](https://img-blog.csdnimg.cn/2020022223110480.png)
2. 欧式距离
L2范数
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200222231139895.png)
3. Jaccard距离
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200222234602903.png)
4. 余弦相似
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200222234624842.png)
5. Pearson相似系数
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200222234832107.png)
6. 相对熵（K-L距离）
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200222235827192.png)
## 文本表示模型有什么？
- 词袋模型，忽略词的顺序，权重是tf-idf
- n-gram模型，连续出现的单词组成词组。优点在于它包含了前N-1个词所能提供的全部信息，这些词对于当前词的出现具有很强的约束力，然而它的缺点是需要相当规模的训练文本来确定模型的参数。当N很大时，模型的参数空间过大。
- 主题模型：能够计算出每篇文章的主题分布
- 词嵌入模型：word2vec将词映射成K维的向量。有两种网络结构，分别是CBOW(上下文预测一个词)和Skip-gram(一个词预测上下文)。损失函数一般用交叉熵

## 图像数据不足时的处理方法
1. 一定程度内的随机旋转、平移、缩放、裁剪、填充、左右翻转
2. 对图像中的像素加噪声扰动，比如高斯白噪声
3. 颜色变换
4. 改变图像的亮度、清晰度、对比度等
5. 生成对抗模型

## 缺失值如何处理？
删除：
填补：离散的用众数、连续的取平均数