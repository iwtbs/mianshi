#  类别不平衡
[细节可以参考](https://mp.weixin.qq.com/s/GrQXHIqBqROxpCjNt4Qs4Q)
## 哪些方法解决类别不平衡问题
1. 欠采样
2. 过采样
3. 代价敏感学习
4. 不均衡学习的评价方法
## 欠采样
直接对训练集中多数类样本进行“欠采样”
1. 随机欠采样方法
会造成一些信息缺失，即将多数类样本删除有可能会导致分类器丢失有关多数类的重要信息
2. 欠采样代表性算法-EasyEnsemble
（1)从多数类中有放回的随机采样n次，每次选取与少数类数目相近的样本个数，那么可以得到n个样本集合记作。
（2)然后，将每一个多数类样本的子集与少数类样本合并并训练出一个模型，可以得到n个模型。
（3)最终将这些模型组合形成一个集成学习系统，最终的模型结果是这n个模型的平均值。
3. 欠采样代表性算法-BalanceCascade
BalanceCascade算法基于Adaboost，将Adaboost作为基分类器，其核心思路是：
（1)在每一轮训练时都使用多数类与少数类数量相等的训练集，训练出一个Adaboost基分类器。
（2)然后使用该分类器对全体多数类进行预测，通过控制分类阈值来控制假正例率（False Positive Rate）,将所有判断正确的类删除。
（3)最后，进入下一轮迭代中，继续降低多数类数量。
## 过采样
对训练集里的少数类进行“过采样”（oversampling），即增加一些少数类样本使得正、反例数目接近，然后再进行学习
1. 随机过采样方法
模型训练复杂度加大，容易造成模型的过拟合问题
2. 过采样代表性算法-SMOTE
(1).对于少数类中的每一个样本，以欧氏距离为标准计算它到少数类样本集中所有样本的距离，得到其k近邻。
(2).根据样本不平衡比例设置一个采样比例以确定采样倍率N，对于每一个少数类样本，从其k近邻中随机选择若干个样本，假设选择的是。
(3).对于每一个随机选出来的近邻，分别与按照如下公式构建新的样本。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200223154428818.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200223154512947.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0MjE5OTU5,size_16,color_FFFFFF,t_70)
## 代价敏感学习
采样算法从数据层面解决不平衡数据的学习问题；在算法层面上解决不平衡数据学习的方法主要是基于代价敏感学习算法
1. 代价矩阵
为了权衡不同类型错误所造成的不同损失，可为错误赋予“非均等代价”
代价敏感学习方法的核心要素是代价矩阵
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200223155114650.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0MjE5OTU5,size_16,color_FFFFFF,t_70)
2. 代价敏感学习方法
基于以上代价敏感矩阵的分析，代价敏感学习方法主要有以下三种实现方式
（1）从学习模型出发，对某一具体学习方法的改造，使之能适应不平衡数据下的学习，研究者们针对不同的学习模型如感知机、支持向量机、决策树、神经网络等分别提出了其代价敏感的版本。以代价敏感的决策树为例，可以从三个方面对其进行改造以适应不平衡数据的学习，这三个方面分别是决策阈值的选择方面、分裂标准的选择方面、剪枝方面，这三个方面都可以将代价矩阵引入
（2）.从贝叶斯风险理论出发，把代价敏感学习看成是分类结果的一种后处理，按照传统方法学习到一个模型，以实现损失最小为目标对结果进行调整，优化公式如下所示。此方法的优点在于它可以不依赖所用的具体分类器，但是缺点也很明显，它要求分类器输出值为概率。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200223155421561.png)
（3）从预处理的角度出发，将代价用于权重调整，使得分类器满足代价敏感的特性，下面讲解一种基于Adaboost的权重更新策略AdaCost算法
AdaCost算法修改了Adaboost算法的权重更新策略，其基本思想是对代价高的误分类样本大大地提高其权重，而对于代价高的正确分类样本适当地降低其权重，使其权重降低相对较小。总体思想是代价高样本权重增加得大降低的慢
## 不平衡学习的评价方法
1. F1度量
2. ROC曲线和AUC面积
ROC曲线和AUC面积可以很好的评价不平衡数据的模型表现
3. G-Mean
## 如何选择方法
(1)在正负样本都非常少的情况下，应该采用数据合成的方式，例如：SMOTE算法
(2)在正负样本都足够多且比例不是特别悬殊的情况下，应该考虑采样的方法或者是加权的方法。